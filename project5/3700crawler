#!/usr/bin/env python3

import argparse, socket, select, ssl, html, html.parser, re, sys
from html.parser import HTMLParser
from urllib.parse import urlparse

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443
csrf_middleware_token = ""
csrf_token = ""
sessionid = ""
frontier = []
crawled = []
flags = []

class Parser(HTMLParser):
	print("in parser")
	def handle_starttag(self, tag, attrs):
		global csrf_middleware_token, frontier, crawled
		attrs = dict(attrs)
		print("TAG: " + str(tag))
		print("ATTRS: " + str(attrs))

		if (csrf_middleware_token == ""):
			if ('name' in attrs) and (attrs['name'] == 'csrfmiddlewaretoken'):
				csrf_middleware_token = attrs['value']
				return
		else:
			if (tag == 'a') and ('href' in attrs) and (attrs['href'] not in crawled) and ('fakebook' in attrs['href']):
				frontier.append(attrs['href'])
	

	def handle_data(self, data):
		global flags
		if ('FLAG' in data):
			flags.append(re.search('FLAG: (.*)', data).group(1))
			# When all flags are found, print them out and exit the program
			if (len(flags) == 5):
				for flag in flags:
					print(flag)
					exit(0)

class Crawler:
	# Initialize variables for the server and port to connect to, and the username and password to use 
	def __init__(self, args):
		if (args.server is None):
			self.server = DEFAULT_SERVER
		else:
			self.server = args.server
		if (args.port is None):
			self.port = DEFAULT_PORT
		else:
			self.port = args.port
		self.username = args.username
		self.password = args.password


	# Establish a TCP socket connection wrapped in TLS
	def socket(self):
		mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
		mysocket.connect((self.server, self.port))
		context = ssl.create_default_context()
		mysocket = context.wrap_socket(mysocket, server_hostname = self.server)
		return mysocket

	def log(self, message):
		sys.stderr.write(message + "\n")
		sys.stderr.flush()


	# Craft and send GET HTML request for given webpage
	def get_request(self, url, csrf_token, sessionid):
		get_request = "GET " + url + " HTTP/1.1\nHost: " + self.server
		if (csrf_token):
			get_request += "\nCookie: csrftoken=" + csrf_token + "; sessionid=" +  sessionid + "\n\n"
		else:
			get_request += "\n\n"
		self.socket.send(get_request.encode('utf-8'))
		get_response = self.socket.recv(65535).decode('utf-8')
		print("GET REQUEST: \n" + str(get_request))
		print("GET RESPONSE: \n" + str(get_response))
		return get_response


	# Craft and send POST HTML request for given webpage
	def post_request(self, path, csrf_middleware_token, csrf_token, sessionid):
		content = "username=" + self.username + "&password=" + self.password + "&csrfmiddlewaretoken=" + csrf_middleware_token + "&next=/fakebook/"
		post_request = "POST " + path + " HTTP/1.1\nHost: " + self.server + "\nContent-Length: " + str(len(content)) + "\nContent-Type: application/x-www-form-urlencoded\nCookie: csrftoken=" + csrf_token + "\n\n" + content + "\n\n"
		self.socket.send(post_request.encode('utf-8'))
		post_response = self.socket.recv(65535).decode('utf-8')
		print("POST REQUEST: " + post_request)
		print("POST RESPONSE: \n" + str(post_response))
		return post_response


	# Use HTTP POST request to log in to Fakebook with provided credentials
	def login(self):
		# GET HTML request the Fakebook login page and receive response from site
		get_response = self.get_request("/accounts/login/?next=/fakebook/", "", "")

		# Get the csrf token and sessionid
		csrf_token = re.search('csrftoken=(.*); expires', get_response).group(1)
		sessionid = re.search('sessionid=(.*); expires', get_response).group(1)

		# Parse the HTML response to find the csrf middleware token
		parser = Parser()
		parser.feed(get_response)
		global csrf_middleware_token, frontier, flags
		
		# POST HTML request to log in to the Fakebook site with given username and password
		post_response = self.post_request("/accounts/login/", csrf_middleware_token, csrf_middleware_token, "")

		# Set new CSRF token and session ID
		csrf_token = re.search('Set-Cookie: csrftoken=(.*); expires', post_response).group(1)
		sessionid = re.search('Set-Cookie: sessionid=(.*); expires', post_response).group(1)

		# Populate frontier with profiles on first Fakebook page
		get_frontier = self.get_request("/fakebook/", csrf_token, sessionid)
		parser.feed(get_frontier)		
		print("FRONTIER: " + str(frontier))


	def run(self):
		# Establish socket connection
		self.socket = self.socket()
		
		# Log in to Fakebook
		self.login()
#		while ((len(frontier) != 0) and (len(flags) < 5)):
			# Call GET on next url in frontier
			

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
